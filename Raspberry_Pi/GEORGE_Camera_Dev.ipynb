{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b2fe26d-5ef6-4783-8f3f-c05e092cd838",
   "metadata": {
    "id": "rOvvWAVTkMR7"
   },
   "source": [
    "# Gradient-Effected Object Recognition Gauge for hive Entrances (GEORGE)\n",
    "Neural-net-powered honeybee hive-mounted pollen, varroa, and wasp counter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c350dd4-f29e-4201-b031-de4d44f5fc21",
   "metadata": {
    "id": "vPs64QA1Zdov"
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e5e496ab-20e3-4e82-95e6-1ba958e02fb9",
   "metadata": {
    "id": "uZcqD4NLdnf4",
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"/home/kevinhardin/.local/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/local/games:/usr/games\")\n",
    "sys.path.append(\"CameraScript\")\n",
    "sys.path.append(\"/home/kevinhardin/Documents/GEORGE\")\n",
    "from CameraScript import takePic\n",
    "from time import sleep, time\n",
    "from datetime import datetime, date\n",
    "import os\n",
    "os.environ[\"LIBCAMERA_LOG_LEVELS\"] = \"2\"\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from pathlib import Path\n",
    "from GEORGE_Library import *\n",
    "%matplotlib inline\n",
    "\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df3d1106-bd69-446b-8a6a-896b43e13ad6",
   "metadata": {},
   "source": [
    "## Define global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "38532072-78de-4340-ad36-15d2ccf0e443",
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "a2082fb1e56fc6cfc91d40820b905267bc1ca468",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "label_id_offset = 1\n",
    "score_threshold = 0.8\n",
    "category_index = {1: {'id': 1, 'name': 'regular'}, 2: {'id': 2, 'name': 'pollen'}, 3: {'id': 3, 'name': 'varroa'}, 4: {'id': 4, 'name': 'wasps'}}\n",
    "model_directory = '/home/kevinhardin/Documents/GEORGE'\n",
    "model_name = 'extract_superimp_model'\n",
    "# model_name = 'model.tflite'\n",
    "model_dest = os.path.join(os.sep, model_directory, model_name)\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_saved_model(model_dest) # path to the SavedModel directory\n",
    "# converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS, tf.lite.OpsSet.SELECT_TF_OPS]\n",
    "# converter._experimental_lower_tensor_list_ops = False\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# Save the model.\n",
    "with open('model2.tflite', 'wb') as f:\n",
    "    f.write(tflite_model)\n",
    "\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ef257e89-c890-4f71-b536-987d750ee7e2",
   "metadata": {},
   "source": [
    "new_model = tf.saved_model.load(model_dest)\n",
    "\n",
    "plt.rcParams['axes.grid'] = False\n",
    "plt.rcParams['xtick.labelsize'] = False\n",
    "plt.rcParams['ytick.labelsize'] = False\n",
    "plt.rcParams['xtick.top'] = False\n",
    "plt.rcParams['xtick.bottom'] = False\n",
    "plt.rcParams['ytick.left'] = False\n",
    "plt.rcParams['ytick.right'] = False\n",
    "plt.rcParams['figure.figsize'] = [15, 15]\n",
    "\n",
    "save_plot = False\n",
    "\n",
    "im, _, _ = takePic()\n",
    "\n",
    "for i in range(3):\n",
    "    image = np.array(im).astype('uint8')[440:, (640 * i):(640 * (i + 1)), :]\n",
    "    ax = plt.subplot(1, 3, i + 1)\n",
    "\n",
    "    bboxes = []\n",
    "    class_ids = []\n",
    "    scores = []\n",
    "\n",
    "    input_tensor = tf.convert_to_tensor(image, dtype=tf.float32)\n",
    "    input_tensor = tf.expand_dims(input_tensor, 0)\n",
    "    detections = new_model.signatures['detect'](input_tensor)\n",
    "\n",
    "    for k in range(len(detections['detection_boxes'][0])):\n",
    "        if detections['detection_scores'][0][k].numpy() >= score_threshold:\n",
    "            y1, x1, y2, x2  = np.array(detections['detection_boxes'][0][k])\n",
    "            bboxes.append([y1, x1, y2, x2])\n",
    "            class_id = detections['detection_classes'][0][k].numpy().astype(np.uint32) + label_id_offset\n",
    "            class_name = category_index[class_id]['name']\n",
    "            score = detections['detection_scores'][0][k].numpy()\n",
    "            class_ids.append(class_id)\n",
    "            scores.append(score)\n",
    "\n",
    "    if not scores == []:\n",
    "        plot_detections(\n",
    "        image,\n",
    "        np.asarray(bboxes),\n",
    "        np.asarray(class_ids),\n",
    "        scores,\n",
    "        category_index)#, figsize=(30, 15))\n",
    "                  \n",
    "plt.suptitle('GEORGE Validation (Score Thresh: %s)' % (score_threshold), fontsize=20)\n",
    "if save_plot:\n",
    "    plt.savefig('GEORGE_Validation_Plot.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41b32dad-9d02-49ea-ba4c-caf082534ba2",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Model provided has model identifier 'ion ', should be 'TFL3'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m interpreter \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlite\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mInterpreter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodel_dest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m input_details \u001b[38;5;241m=\u001b[39m interpreter\u001b[38;5;241m.\u001b[39mget_input_details()\n\u001b[1;32m      3\u001b[0m output_details \u001b[38;5;241m=\u001b[39m interpreter\u001b[38;5;241m.\u001b[39mget_output_details()\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/tensorflow/lite/python/interpreter.py:490\u001b[0m, in \u001b[0;36mInterpreter.__init__\u001b[0;34m(self, model_path, model_content, experimental_delegates, num_threads, experimental_op_resolver_type, experimental_preserve_all_tensors, experimental_disable_delegate_clustering, experimental_default_delegate_latest_features)\u001b[0m\n\u001b[1;32m    484\u001b[0m custom_op_registerers_by_name \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    485\u001b[0m     x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_custom_op_registerers \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mstr\u001b[39m)\n\u001b[1;32m    486\u001b[0m ]\n\u001b[1;32m    487\u001b[0m custom_op_registerers_by_func \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    488\u001b[0m     x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_custom_op_registerers \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mstr\u001b[39m)\n\u001b[1;32m    489\u001b[0m ]\n\u001b[0;32m--> 490\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_interpreter \u001b[38;5;241m=\u001b[39m \u001b[43m_interpreter_wrapper\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCreateWrapperFromFile\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    491\u001b[0m \u001b[43m    \u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfspath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    492\u001b[0m \u001b[43m    \u001b[49m\u001b[43mop_resolver_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcustom_op_registerers_by_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcustom_op_registerers_by_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    495\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexperimental_preserve_all_tensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    496\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexperimental_disable_delegate_clustering\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    497\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnum_threads\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    498\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexperimental_default_delegate_latest_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    499\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_interpreter:\n\u001b[1;32m    501\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFailed to open \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(model_path))\n",
      "\u001b[0;31mValueError\u001b[0m: Model provided has model identifier 'ion ', should be 'TFL3'\n"
     ]
    }
   ],
   "source": [
    "interpreter = tf.lite.Interpreter(model_path = model_dest)\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "#print results\n",
    "print(\"Input Shape:\", input_details[0]['shape'])\n",
    "print(\"Input Type:\", input_details[0]['dtype'])\n",
    "print(\"Output Shape:\", output_details[0]['shape'])\n",
    "print(\"Output Type:\", output_details[0]['dtype'])\n",
    "\n",
    "plt.rcParams['axes.grid'] = False\n",
    "plt.rcParams['xtick.labelsize'] = False\n",
    "plt.rcParams['ytick.labelsize'] = False\n",
    "plt.rcParams['xtick.top'] = False\n",
    "plt.rcParams['xtick.bottom'] = False\n",
    "plt.rcParams['ytick.left'] = False\n",
    "plt.rcParams['ytick.right'] = False\n",
    "plt.rcParams['figure.figsize'] = [15, 15]\n",
    "\n",
    "save_plot = False\n",
    "\n",
    "im, _, _ = takePic()\n",
    "\n",
    "# for i in range(3):\n",
    "#     image = np.array(im).astype('uint8')[440:, (640 * i):(640 * (i + 1)), :]\n",
    "#     ax = plt.subplot(1, 3, i + 1)\n",
    "\n",
    "#     bboxes = []\n",
    "#     class_ids = []\n",
    "#     scores = []\n",
    "\n",
    "#     input_tensor = tf.convert_to_tensor(image, dtype=tf.float32)\n",
    "#     input_tensor = tf.expand_dims(input_tensor, 0)\n",
    "#     detections = new_model.signatures['detect'](input_tensor)\n",
    "\n",
    "#     for k in range(len(detections['detection_boxes'][0])):\n",
    "#         if detections['detection_scores'][0][k].numpy() >= score_threshold:\n",
    "#             y1, x1, y2, x2  = np.array(detections['detection_boxes'][0][k])\n",
    "#             bboxes.append([y1, x1, y2, x2])\n",
    "#             class_id = detections['detection_classes'][0][k].numpy().astype(np.uint32) + label_id_offset\n",
    "#             class_name = category_index[class_id]['name']\n",
    "#             score = detections['detection_scores'][0][k].numpy()\n",
    "#             class_ids.append(class_id)\n",
    "#             scores.append(score)\n",
    "\n",
    "#     if not scores == []:\n",
    "#         plot_detections(\n",
    "#         image,\n",
    "#         np.asarray(bboxes),\n",
    "#         np.asarray(class_ids),\n",
    "#         scores,\n",
    "#         category_index)#, figsize=(30, 15))\n",
    "                  \n",
    "# plt.suptitle('GEORGE Validation (Score Thresh: %s)' % (score_threshold), fontsize=20)\n",
    "# if save_plot:\n",
    "#     plt.savefig('GEORGE_Validation_Plot.png')\n",
    "# plt.show()\n",
    "\n",
    "for i in range(3):\n",
    "    start_time = time.time()\n",
    "\n",
    "    new_img = np.array(im).astype('uint8')[440:, (640 * i):(640 * (i + 1)), :]\n",
    "    new_img /= 255\n",
    "    new_img = np.expand_dims(new_img, axis=0)\n",
    "\n",
    "    # input_details[0]['index'] = the index which accepts the input\n",
    "    interpreter.set_tensor(input_details[0]['index'], new_img)\n",
    "\n",
    "    # run the inference\n",
    "    interpreter.invoke()\n",
    "\n",
    "    # The function `get_tensor()` returns a copy of the tensor data.\n",
    "    # Use `tensor()` in order to get a pointer to the tensor.\n",
    "    output_data = interpreter.get_tensor(output_details[0]['index'])\n",
    "    print(output_data)\n",
    "\n",
    "    #stop time\n",
    "    elapsed_ms = (time.time() - start_time) * 1000\n",
    "\n",
    "    #print predict classes\n",
    "    classes = np.argmax(output_data, axis = 1)\n",
    "    print(\"elapsed time: \", elapsed_ms, \" , predict class number: \", classes, \" ,is class name: \", classes_names[classes[0]], sep='')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
