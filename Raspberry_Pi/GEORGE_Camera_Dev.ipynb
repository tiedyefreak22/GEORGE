{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b2fe26d-5ef6-4783-8f3f-c05e092cd838",
   "metadata": {
    "id": "rOvvWAVTkMR7"
   },
   "source": [
    "# Gradient-Effected Object Recognition Gauge for hive Entrances (GEORGE)\n",
    "Neural-net-powered honeybee hive-mounted pollen, varroa, and wasp counter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c350dd4-f29e-4201-b031-de4d44f5fc21",
   "metadata": {
    "id": "vPs64QA1Zdov"
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e5e496ab-20e3-4e82-95e6-1ba958e02fb9",
   "metadata": {
    "id": "uZcqD4NLdnf4",
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"/home/kevinhardin/.local/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/local/games:/usr/games\")\n",
    "sys.path.append(\"CameraScript\")\n",
    "sys.path.append(\"/home/kevinhardin/Documents/GEORGE\")\n",
    "# sys.path.append(\"/Users/kevinhardin/Documents/GitHub/GEORGE\")\n",
    "from CameraScript import takePic\n",
    "from time import sleep, time\n",
    "from datetime import datetime, date\n",
    "import os\n",
    "os.environ[\"LIBCAMERA_LOG_LEVELS\"] = \"2\"\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from pathlib import Path\n",
    "from GEORGE_Library import *\n",
    "%matplotlib inline\n",
    "\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d0d4881f-0e78-4eb6-b9f7-798b05154d33",
   "metadata": {},
   "source": [
    "model_directory = os.path.join(os.getcwd(), \"..\")\n",
    "model_name = 'extract_superimp_model'\n",
    "# model_name = 'model.tflite'\n",
    "model_dest = os.path.join(os.sep, model_directory, model_name)\n",
    "print(model_dest)\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_saved_model(model_dest) # path to the SavedModel directory\n",
    "# converter.experimental_enable_resource_variables = True\n",
    "# converter.experimental_new_converter = True\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS, tf.lite.OpsSet.SELECT_TF_OPS]\n",
    "converter._experimental_lower_tensor_list_ops = False\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# Save the model.\n",
    "with open('model2.tflite', 'wb') as f:\n",
    "    f.write(tflite_model)\n",
    "\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df3d1106-bd69-446b-8a6a-896b43e13ad6",
   "metadata": {},
   "source": [
    "## Define global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "38532072-78de-4340-ad36-15d2ccf0e443",
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "a2082fb1e56fc6cfc91d40820b905267bc1ca468",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "label_id_offset = 1\n",
    "score_threshold = 0.8\n",
    "category_index = {1: {'id': 1, 'name': 'regular'}, 2: {'id': 2, 'name': 'pollen'}, 3: {'id': 3, 'name': 'varroa'}, 4: {'id': 4, 'name': 'wasps'}}\n",
    "model_directory = \"/home/kevinhardin/Documents/GEORGE/Raspberry_Pi\"\n",
    "# model_name = 'extract_superimp_model'\n",
    "model_name = 'model2.tflite'\n",
    "model_dest = os.path.join(os.sep, model_directory, model_name)\n",
    "\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ef257e89-c890-4f71-b536-987d750ee7e2",
   "metadata": {},
   "source": [
    "new_model = tf.saved_model.load(model_dest)\n",
    "\n",
    "plt.rcParams['axes.grid'] = False\n",
    "plt.rcParams['xtick.labelsize'] = False\n",
    "plt.rcParams['ytick.labelsize'] = False\n",
    "plt.rcParams['xtick.top'] = False\n",
    "plt.rcParams['xtick.bottom'] = False\n",
    "plt.rcParams['ytick.left'] = False\n",
    "plt.rcParams['ytick.right'] = False\n",
    "plt.rcParams['figure.figsize'] = [15, 15]\n",
    "\n",
    "save_plot = False\n",
    "\n",
    "im, _, _ = takePic()\n",
    "\n",
    "for i in range(3):\n",
    "    image = np.array(im).astype('uint8')[440:, (640 * i):(640 * (i + 1)), :]\n",
    "    ax = plt.subplot(1, 3, i + 1)\n",
    "\n",
    "    bboxes = []\n",
    "    class_ids = []\n",
    "    scores = []\n",
    "\n",
    "    input_tensor = tf.convert_to_tensor(image, dtype=tf.float32)\n",
    "    input_tensor = tf.expand_dims(input_tensor, 0)\n",
    "    detections = new_model.signatures['detect'](input_tensor)\n",
    "\n",
    "    for k in range(len(detections['detection_boxes'][0])):\n",
    "        if detections['detection_scores'][0][k].numpy() >= score_threshold:\n",
    "            y1, x1, y2, x2  = np.array(detections['detection_boxes'][0][k])\n",
    "            bboxes.append([y1, x1, y2, x2])\n",
    "            class_id = detections['detection_classes'][0][k].numpy().astype(np.uint32) + label_id_offset\n",
    "            class_name = category_index[class_id]['name']\n",
    "            score = detections['detection_scores'][0][k].numpy()\n",
    "            class_ids.append(class_id)\n",
    "            scores.append(score)\n",
    "\n",
    "    if not scores == []:\n",
    "        plot_detections(\n",
    "        image,\n",
    "        np.asarray(bboxes),\n",
    "        np.asarray(class_ids),\n",
    "        scores,\n",
    "        category_index)#, figsize=(30, 15))\n",
    "                  \n",
    "plt.suptitle('GEORGE Validation (Score Thresh: %s)' % (score_threshold), fontsize=20)\n",
    "if save_plot:\n",
    "    plt.savefig('GEORGE_Validation_Plot.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "41b32dad-9d02-49ea-ba4c-caf082534ba2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Shape: [  1 640 640   3]\n",
      "Input Type: <class 'numpy.float32'>\n",
      "Output Shape: [1 1 4]\n",
      "Output Type: <class 'numpy.float32'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Created TensorFlow Lite delegate for select TF ops.\n",
      "INFO: TfLiteFlexDelegate delegate: 12 nodes delegated out of 406 nodes with 4 partitions.\n",
      "\n",
      "2025-08-24 12:37:12.970449: E tensorflow/core/framework/node_def_util.cc:676] NodeDef mentions attribute use_inter_op_parallelism which is not in the op definition: Op<name=TensorListReserve; signature=element_shape:shape_type, num_elements:int32 -> handle:variant; attr=element_dtype:type; attr=shape_type:type,allowed=[DT_INT32, DT_INT64]> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node TensorListReserve}}\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'takePic' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 21\u001b[0m\n\u001b[1;32m     17\u001b[0m plt\u001b[38;5;241m.\u001b[39mrcParams[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfigure.figsize\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m15\u001b[39m, \u001b[38;5;241m15\u001b[39m]\n\u001b[1;32m     19\u001b[0m save_plot \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m im, _, _ \u001b[38;5;241m=\u001b[39m \u001b[43mtakePic\u001b[49m()\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# for i in range(3):\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m#     image = np.array(im).astype('uint8')[440:, (640 * i):(640 * (i + 1)), :]\u001b[39;00m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m#     ax = plt.subplot(1, 3, i + 1)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m#     plt.savefig('GEORGE_Validation_Plot.png')\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m# plt.show()\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m3\u001b[39m):\n",
      "\u001b[0;31mNameError\u001b[0m: name 'takePic' is not defined"
     ]
    }
   ],
   "source": [
    "interpreter = tf.lite.Interpreter(model_path = model_dest)\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "#print results\n",
    "print(\"Input Shape:\", input_details[0]['shape'])\n",
    "print(\"Input Type:\", input_details[0]['dtype'])\n",
    "print(\"Output Shape:\", output_details[0]['shape'])\n",
    "print(\"Output Type:\", output_details[0]['dtype'])\n",
    "\n",
    "plt.rcParams['axes.grid'] = False\n",
    "plt.rcParams['xtick.labelsize'] = False\n",
    "plt.rcParams['ytick.labelsize'] = False\n",
    "plt.rcParams['xtick.top'] = False\n",
    "plt.rcParams['xtick.bottom'] = False\n",
    "plt.rcParams['ytick.left'] = False\n",
    "plt.rcParams['ytick.right'] = False\n",
    "plt.rcParams['figure.figsize'] = [15, 15]\n",
    "\n",
    "save_plot = False\n",
    "\n",
    "im, _, _ = takePic()\n",
    "\n",
    "# for i in range(3):\n",
    "#     image = np.array(im).astype('uint8')[440:, (640 * i):(640 * (i + 1)), :]\n",
    "#     ax = plt.subplot(1, 3, i + 1)\n",
    "\n",
    "#     bboxes = []\n",
    "#     class_ids = []\n",
    "#     scores = []\n",
    "\n",
    "#     input_tensor = tf.convert_to_tensor(image, dtype=tf.float32)\n",
    "#     input_tensor = tf.expand_dims(input_tensor, 0)\n",
    "#     detections = new_model.signatures['detect'](input_tensor)\n",
    "\n",
    "#     for k in range(len(detections['detection_boxes'][0])):\n",
    "#         if detections['detection_scores'][0][k].numpy() >= score_threshold:\n",
    "#             y1, x1, y2, x2  = np.array(detections['detection_boxes'][0][k])\n",
    "#             bboxes.append([y1, x1, y2, x2])\n",
    "#             class_id = detections['detection_classes'][0][k].numpy().astype(np.uint32) + label_id_offset\n",
    "#             class_name = category_index[class_id]['name']\n",
    "#             score = detections['detection_scores'][0][k].numpy()\n",
    "#             class_ids.append(class_id)\n",
    "#             scores.append(score)\n",
    "\n",
    "#     if not scores == []:\n",
    "#         plot_detections(\n",
    "#         image,\n",
    "#         np.asarray(bboxes),\n",
    "#         np.asarray(class_ids),\n",
    "#         scores,\n",
    "#         category_index)#, figsize=(30, 15))\n",
    "                  \n",
    "# plt.suptitle('GEORGE Validation (Score Thresh: %s)' % (score_threshold), fontsize=20)\n",
    "# if save_plot:\n",
    "#     plt.savefig('GEORGE_Validation_Plot.png')\n",
    "# plt.show()\n",
    "\n",
    "for i in range(3):\n",
    "    start_time = time.time()\n",
    "\n",
    "    new_img = np.array(im).astype('uint8')[440:, (640 * i):(640 * (i + 1)), :]\n",
    "    new_img /= 255\n",
    "    new_img = np.expand_dims(new_img, axis=0)\n",
    "\n",
    "    # input_details[0]['index'] = the index which accepts the input\n",
    "    interpreter.set_tensor(input_details[0]['index'], new_img)\n",
    "\n",
    "    # run the inference\n",
    "    interpreter.invoke()\n",
    "\n",
    "    # The function `get_tensor()` returns a copy of the tensor data.\n",
    "    # Use `tensor()` in order to get a pointer to the tensor.\n",
    "    output_data = interpreter.get_tensor(output_details[0]['index'])\n",
    "    print(output_data)\n",
    "\n",
    "    #stop time\n",
    "    elapsed_ms = (time.time() - start_time) * 1000\n",
    "\n",
    "    #print predict classes\n",
    "    classes = np.argmax(output_data, axis = 1)\n",
    "    print(\"elapsed time: \", elapsed_ms, \" , predict class number: \", classes, \" ,is class name: \", classes_names[classes[0]], sep='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b1d923-45a8-4004-a473-131bf6e08144",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
