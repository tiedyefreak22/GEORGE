{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8206c462-5550-4b31-9122-4d5eb0e365a9",
   "metadata": {
    "id": "rOvvWAVTkMR7"
   },
   "source": [
    "# Gradient-Effected Object Recognition Gauge for hive Entrances (GEORGE)\n",
    "Neural-net-powered honeybee hive-mounted pollen, varroa, and wasp counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdab4501-43e2-4cf9-a4c1-580ed357f021",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from PIL import Image, ImageOps\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image, ImageOps\n",
    "from picamera import PiCamera\n",
    "import GEORGE_Library as GEORGE\n",
    "\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e205ff-27eb-4e34-ad1c-af063b7e8bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"#set classes names\")\n",
    "classes_names = ['animals', 'other', 'person'] #you can change classes\n",
    "\n",
    "print(\"#load model\")\n",
    "TF_LITE_MODEL_FILE_NAME = \"animall_person_other_v2_fine_tuned.tflite\" #you can change model\n",
    "interpreter = tf.lite.Interpreter(model_path = TF_LITE_MODEL_FILE_NAME)\n",
    "\n",
    "print(\"#Check Input Tensor Shape\")\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "#print results\n",
    "print(\"Input Shape:\", input_details[0]['shape'])\n",
    "print(\"Input Type:\", input_details[0]['dtype'])\n",
    "print(\"Output Shape:\", output_details[0]['shape'])\n",
    "print(\"Output Type:\", output_details[0]['dtype'])\n",
    "\n",
    "print(\"#Resize Tensor Shape\")\n",
    "interpreter.resize_tensor_input(input_details[0]['index'], (1, 299, 299, 3)) #you can change to your parameters\n",
    "interpreter.resize_tensor_input(output_details[0]['index'], (1, 3)) #you can change to your parameters\n",
    "interpreter.allocate_tensors()\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "#print results\n",
    "print(\"Input Shape:\", input_details[0]['shape'])\n",
    "print(\"Input Type:\", input_details[0]['dtype'])\n",
    "print(\"Output Shape:\", output_details[0]['shape'])\n",
    "print(\"Output Type:\", output_details[0]['dtype'])\n",
    "\n",
    "print(\"# input details\")\n",
    "print(input_details)\n",
    "print(\"# output details\")\n",
    "print(output_details)\n",
    "\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de06fa9b-d5ed-48a9-aa81-c7beecda2bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    #start time\n",
    "    start_time = time.time()\n",
    "\n",
    "    camera = PiCamera()\n",
    "    camera.capture('image.jpeg')\n",
    "    img_path = 'image.jpeg'\n",
    "\n",
    "    #resize image\n",
    "    img = load_img(img_path, target_size=(299, 299))\n",
    "    new_img = image.img_to_array(img)\n",
    "    new_img /= 255\n",
    "    new_img = np.expand_dims(new_img, axis=0)\n",
    "\n",
    "    # input_details[0]['index'] = the index which accepts the input\n",
    "    interpreter.set_tensor(input_details[0]['index'], new_img)\n",
    "\n",
    "    # run the inference\n",
    "    interpreter.invoke()\n",
    "\n",
    "    # The function `get_tensor()` returns a copy of the tensor data.\n",
    "    # Use `tensor()` in order to get a pointer to the tensor.\n",
    "    output_data = interpreter.get_tensor(output_details[0]['index'])\n",
    "    #print(output_data)    \n",
    "\n",
    "    #stop time\n",
    "    elapsed_ms = (time.time() - start_time) * 1000\n",
    "\n",
    "    #print predict classes\n",
    "    classes = np.argmax(output_data, axis = 1)\n",
    "    print(\"elapsed time: \", elapsed_ms, \" , predict class number: \", classes, \" ,is class name: \", classes_names[classes[0]], sep='')\n",
    "\n",
    "    #close camera\n",
    "    camera.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
