{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "cb2e73fe056a3dda7eb48eeac2facf0c441816d1"
   },
   "source": [
    "# <a id='21'>Load packages</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "af08260bfbe163f9132f39d09627899bbc4c1dae",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-2.12.1.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "import random\n",
    "from pathlib import Path\n",
    "import imageio\n",
    "import skimage\n",
    "import skimage.io\n",
    "import skimage.transform\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.graph_objs as go\n",
    "import plotly.figure_factory as ff\n",
    "from plotly import tools\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "init_notebook_mode(connected=True)\n",
    "import scipy\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Flatten, MaxPool2D, Dropout, BatchNormalization,LeakyReLU\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ModelCheckpoint, Callback, EarlyStopping, ReduceLROnPlateau, LearningRateScheduler\n",
    "from keras.utils import to_categorical\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "import tensorflow\n",
    "\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "a2082fb1e56fc6cfc91d40820b905267bc1ca468",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "IMAGE_PATH = 'Yang Model Training/bee_imgs/bee_imgs/'\n",
    "IMAGE_WIDTH = 100\n",
    "IMAGE_HEIGHT = 100\n",
    "IMAGE_CHANNELS = 3\n",
    "RANDOM_STATE = 2018\n",
    "TEST_SIZE = 0.2\n",
    "VAL_SIZE = 0.2\n",
    "CONV_2D_DIM_1 = 16\n",
    "CONV_2D_DIM_2 = 16\n",
    "CONV_2D_DIM_3 = 32\n",
    "CONV_2D_DIM_4 = 64\n",
    "MAX_POOL_DIM = 2\n",
    "KERNEL_SIZE = 3\n",
    "BATCH_SIZE = 32\n",
    "NO_EPOCHS_1 = 5\n",
    "NO_EPOCHS_2 = 10\n",
    "NO_EPOCHS_3 = 50\n",
    "PATIENCE = 5\n",
    "VERBOSE = 1\n",
    "\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "307f656565365ff05faf226e5a447875dd0dfead"
   },
   "source": [
    "# <a id='22'>Load the data</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "241b8735a85a25e16421fda8c35bc3d3c69e7ea8"
   },
   "source": [
    "There is a dataset file and a folder with images.  \n",
    "\n",
    "Let's load the dataset file first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "d7b9f11a014428e56e422d97a5b3ef70efec007e",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "honey_bee_df=pd.read_csv('Yang Model Training/bee_data.csv')\n",
    "\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "5b4405ddcce03ee722f05234d508188997817f8d"
   },
   "source": [
    "There are 5172 rows and 9 columns. Let's look to the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c2a5e2401b418f1723c859ee9e0b4ad5071e4a82"
   },
   "source": [
    "# <a id='4'>Subspecies classification</a>\n",
    "\n",
    "Our objective is to use the images that we investigated until now to correctly identify the subspecies. We have a unique dataset and we will have to split this dataset in **train** and **test**. The **train** set will be used for training a model and the test will be used for testing the model accuracy against new, fresh data, not used in training.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "e8c0a6df4bb85bcdf90f7c908decab07304d660f"
   },
   "source": [
    "## <a id='40'>Split the data</a>  \n",
    "\n",
    "First, we split the whole dataset in train and test. We will use **random_state** to ensure reproductibility of results.   \n",
    "\n",
    "The train-test split is **80%** for training set and **20%** for test set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "352d452d5212d8c9eff074f11820b03a0d44387b"
   },
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(honey_bee_df, test_size=TEST_SIZE, random_state=RANDOM_STATE, \n",
    "                                     stratify=honey_bee_df['subspecies'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "856060cc500db00e472b7755c91aba20c953a5f6"
   },
   "source": [
    "Next, we will split further the **train** set in **train** and **validation**. We want to use as well a validation set to be able to measure not only how well fits the model the train data during training (or how well `learns` the training data) but also how well the model is able to generalize so that we are able to understands not only the bias but also the variance of the model.  \n",
    "\n",
    "The train-validation split is **80%** for training set and **20%** for validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "83d0be04ae5a4ad5834631bf18e21917d6313bcd"
   },
   "outputs": [],
   "source": [
    "train_df, val_df = train_test_split(train_df, test_size=VAL_SIZE, random_state=RANDOM_STATE, stratify=train_df['subspecies'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "0dcaa8c2c5423ab8fc2898d4a4aa937801592c2c"
   },
   "source": [
    "Let's check the shape of the three datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "8247f70b4deb4600fe322f004733234ed37617f0"
   },
   "outputs": [],
   "source": [
    "print(\"Train set rows: {}\".format(train_df.shape[0]))\n",
    "print(\"Test  set rows: {}\".format(test_df.shape[0]))\n",
    "print(\"Val   set rows: {}\".format(val_df.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "ee768c083f40fcbd109425182bc55ce86173b69d"
   },
   "source": [
    "We are now ready to start building our first model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "d76e822dd76565d29fcfed323cb034939f307581"
   },
   "source": [
    "## <a id='41'>Build a baseline model</a>    \n",
    "\n",
    "\n",
    "Next step in our creation of a predictive model is to create a simple model, a **baseline model**.  \n",
    "\n",
    " Why start with a simple model (as simple as possible, but not simpler :-) )?\n",
    " \n",
    " With a simple model, we can get fast insight in how well will the data predict our target value. Looking to the training results (the training error and accuracy, the validation error and accuracy), we can understand if we need to add more data (because the training accuracy is small) or if we need to optimize the model (by adding more convolutional layers) or if we need to add Dropout layers (because the validation error is increasing after few steps - the model is overfitting) etc.\n",
    " \n",
    "Let's define few auxiliary functions that we will need for creation of our models.\n",
    "\n",
    "A function for reading images from the image files, scale all images to 100 x 100 x 3 (channels)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "f80b4e20e98ce5bf328fba3a22457c4a994de06b"
   },
   "outputs": [],
   "source": [
    "def read_image(file_name):\n",
    "    image = skimage.io.imread(IMAGE_PATH + file_name)\n",
    "    image = skimage.transform.resize(image, (IMAGE_WIDTH, IMAGE_HEIGHT), mode='reflect')\n",
    "    return image[:,:,:IMAGE_CHANNELS]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "e396e0cd23633af2169e4d50985f1987654205a9"
   },
   "source": [
    "A function to create the dummy variables corresponding to the categorical target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "0f7a2146ca93aef9367ecd64300980005d89911b"
   },
   "outputs": [],
   "source": [
    "def categories_encoder(dataset, var='subspecies'):\n",
    "    X = np.stack(dataset['file'].apply(read_image))\n",
    "    y = pd.get_dummies(dataset[var], drop_first=False)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "b40c205d5189b23cbbc4ef0cda8798721d504ff9"
   },
   "source": [
    "Let's populate now the train, val and test sets with the image data and create the  dummy variables corresponding to the categorical target variable, in our case `subspecies`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "70acefcd6dc5d494b1c7db6dc90bae5f8c856d94"
   },
   "outputs": [],
   "source": [
    "X_train, y_train = categories_encoder(train_df)\n",
    "X_val, y_val = categories_encoder(val_df)\n",
    "X_test, y_test = categories_encoder(test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "5093354dc9c7f0510ba54a254690db45e38d0bcc"
   },
   "source": [
    "Now we are ready to start creating our model.  \n",
    "\n",
    "We will add the folllowing elements to our model: \n",
    "* One convolutional layer, with 16 filters of dimmension 3;  \n",
    "* One maxpoll2d layer, with reduction factor 2;  \n",
    "* One convolutional layer, with 16 filters of dimmension 3;  \n",
    "* A flatten layer;  \n",
    "* A dense layer;  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "bd7147baf9c45217988df92cf631202684fb3609"
   },
   "outputs": [],
   "source": [
    "model1=Sequential()\n",
    "model1.add(Conv2D(CONV_2D_DIM_1, kernel_size=KERNEL_SIZE, input_shape=(IMAGE_WIDTH, IMAGE_HEIGHT,IMAGE_CHANNELS), activation='relu', padding='same'))\n",
    "model1.add(MaxPool2D(MAX_POOL_DIM))\n",
    "model1.add(Conv2D(CONV_2D_DIM_2, kernel_size=KERNEL_SIZE, activation='relu', padding='same'))\n",
    "model1.add(Flatten())\n",
    "model1.add(Dense(y_train.columns.size, activation='softmax'))\n",
    "model1.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "046612eda2408801ded03cc6a5e2357a99298969"
   },
   "outputs": [],
   "source": [
    "model1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "725cef4194ab0eeb3901ba68f5226aa94ccda331"
   },
   "source": [
    "We are also using a **ImageDataGenerator** that creates random variation of the training dataset, by applying various techniques, including:\n",
    "* rotation (in a range of 0-180 degrees) of the original images;  \n",
    "- zoom (10%);  \n",
    "- shift in horizontal and in vertical direction (10%);  \n",
    "- horizontal and vertical flip;  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "d2e402a92832cfd95cb3668431482d40854bb93a"
   },
   "outputs": [],
   "source": [
    "image_generator = ImageDataGenerator(\n",
    "        featurewise_center=False,\n",
    "        samplewise_center=False,\n",
    "        featurewise_std_normalization=False,\n",
    "        samplewise_std_normalization=False,\n",
    "        zca_whitening=False,\n",
    "        rotation_range=180,\n",
    "        zoom_range = 0.1, \n",
    "        width_shift_range=0.1,\n",
    "        height_shift_range=0.1, \n",
    "        horizontal_flip=True,\n",
    "        vertical_flip=True)\n",
    "image_generator.fit(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "0149020f748dc9eaa89ebf732829031d6d9d35a2"
   },
   "source": [
    "We train the first model using **fit_generator** and a predefined batch size. The **steps_per_epoch** is calculated to be size of the training set divided by the batch size. We are using the predefined epoch number for this first experiment (5 steps) and as well validation, using the validation set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "19ac76b9eed3495049a0546402368a529c5db2cb"
   },
   "outputs": [],
   "source": [
    "train_model1  = model1.fit_generator(image_generator.flow(X_train, y_train, batch_size=BATCH_SIZE),\n",
    "                        epochs=NO_EPOCHS_1,\n",
    "                        validation_data=[X_val, y_val],\n",
    "                        steps_per_epoch=len(X_train)/BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "5837b3e9cb131fab2c58f4b9de92f147f48b59ae"
   },
   "source": [
    "<a href=\"#0\"><font size=\"1\">Go to top</font></a>  \n",
    "\n",
    "\n",
    "## <a id='42'>Model evaluation</a> \n",
    "\n",
    "\n",
    "Let's start by plotting the loss error for the train and validation set. \n",
    "We define a function to visualize these values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "a87e3beea44a87a806893b798a38d26904d10718"
   },
   "outputs": [],
   "source": [
    "def create_trace(x,y,ylabel,color):\n",
    "        trace = go.Scatter(\n",
    "            x = x,y = y,\n",
    "            name=ylabel,\n",
    "            marker=dict(color=color),\n",
    "            mode = \"markers+lines\",\n",
    "            text=x\n",
    "        )\n",
    "        return trace\n",
    "    \n",
    "def plot_accuracy_and_loss(train_model):\n",
    "    hist = train_model.history\n",
    "    acc = hist['acc']\n",
    "    val_acc = hist['val_acc']\n",
    "    loss = hist['loss']\n",
    "    val_loss = hist['val_loss']\n",
    "    epochs = list(range(1,len(acc)+1))\n",
    "    #define the traces\n",
    "    trace_ta = create_trace(epochs,acc,\"Training accuracy\", \"Green\")\n",
    "    trace_va = create_trace(epochs,val_acc,\"Validation accuracy\", \"Red\")\n",
    "    trace_tl = create_trace(epochs,loss,\"Training loss\", \"Blue\")\n",
    "    trace_vl = create_trace(epochs,val_loss,\"Validation loss\", \"Magenta\")\n",
    "    fig = tools.make_subplots(rows=1,cols=2, subplot_titles=('Training and validation accuracy',\n",
    "                                                             'Training and validation loss'))\n",
    "    #add traces to the figure\n",
    "    fig.append_trace(trace_ta,1,1)\n",
    "    fig.append_trace(trace_va,1,1)\n",
    "    fig.append_trace(trace_tl,1,2)\n",
    "    fig.append_trace(trace_vl,1,2)\n",
    "    #set the layout for the figure\n",
    "    fig['layout']['xaxis'].update(title = 'Epoch')\n",
    "    fig['layout']['xaxis2'].update(title = 'Epoch')\n",
    "    fig['layout']['yaxis'].update(title = 'Accuracy', range=[0,1])\n",
    "    fig['layout']['yaxis2'].update(title = 'Loss', range=[0,1])\n",
    "    #plot\n",
    "    iplot(fig, filename='accuracy-loss')\n",
    "\n",
    "plot_accuracy_and_loss(train_model1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "a77c0127288f090233e70831e6b909c1618efa35"
   },
   "source": [
    "\n",
    "Let's continue by evaluating the **test** set **loss** and **accuracy**. We will use here the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "1f54e33fcba0e3054d364f35a22f69ef350e8e0d"
   },
   "outputs": [],
   "source": [
    "score = model1.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "46cd7e86e92ac2ec484f0c38c451465cc16a2736"
   },
   "source": [
    "Let's check also the test accuracy per class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "55e96cfdaf488df5bc3d5511fa062563926227ad"
   },
   "outputs": [],
   "source": [
    "def test_accuracy_report(model):\n",
    "    predicted = model.predict(X_test)\n",
    "    test_predicted = np.argmax(predicted, axis=1)\n",
    "    test_truth = np.argmax(y_test.values, axis=1)\n",
    "    print(metrics.classification_report(test_truth, test_predicted, target_names=y_test.columns)) \n",
    "    test_res = model.evaluate(X_test, y_test.values, verbose=0)\n",
    "    print('Loss function: %s, accuracy:' % test_res[0], test_res[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "68c06c36ae2f89e070c878bf5f660e765d23878b"
   },
   "outputs": [],
   "source": [
    "test_accuracy_report(model1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "28293f20eb559420e61e052397bd998fe6e6ff05"
   },
   "source": [
    "We used a simple model. We separated 20% of the data for testing. From the training data, 80% is used for actual training and 20% for testing.   \n",
    "The data is unbalanced with respect of the classes of subspecies.   \n",
    "The accuracy of the training set obtained after only 5 epochs was 0.84, with a loss of 0.38.    \n",
    "The accuracy of the validation set remained around 0.84 and the loss remained constant after epoch 4.  \n",
    "\n",
    "Adding additional data will only slightly increase the accuracy of the training set (it is already very good).   \n",
    "To reduce the loss of the validation set (which is a sign of overfitting), we can have three strategies:  \n",
    "* add Dropout layers;  \n",
    "* introduce strides;  \n",
    "* modify the learning rate during the training;  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "74de02a417db465b77495147c810911d81f491a9"
   },
   "source": [
    "<a href=\"#0\"><font size=\"1\">Go to top</font></a>  \n",
    "\n",
    "\n",
    "## <a id='43'>Add Dropout</a>  \n",
    "\n",
    "We add two Dropout layers.  The role of the Dropout layers is to reduce the overfitting, by dropping, each training epoch, a certain percent of the nodes connections (by rotation). This is equivalent of using less training data and in the same time training the network with various data as well as using `parallel` alternative networks, thus reducing the likelihood that the network will overfit the train data.  \n",
    "\n",
    "The definition of the second model is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "ca30aceff3500c10383761962a7908f0b2b558f3"
   },
   "outputs": [],
   "source": [
    "model2=Sequential()\n",
    "model2.add(Conv2D(CONV_2D_DIM_1, kernel_size=KERNEL_SIZE, input_shape=(IMAGE_WIDTH, IMAGE_HEIGHT,IMAGE_CHANNELS), activation='relu', padding='same'))\n",
    "model2.add(MaxPool2D(MAX_POOL_DIM))\n",
    "# Add dropouts to the model\n",
    "model2.add(Dropout(0.4))\n",
    "model2.add(Conv2D(CONV_2D_DIM_2, kernel_size=KERNEL_SIZE, activation='relu', padding='same'))\n",
    "# Add dropouts to the model\n",
    "model2.add(Dropout(0.4))\n",
    "model2.add(Flatten())\n",
    "model2.add(Dense(y_train.columns.size, activation='softmax'))\n",
    "model2.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "cff8a87a7e837de5dd0b001ace6249933027d95b"
   },
   "source": [
    "Let's inspect the new model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "63dff8b355758d2d55d3e7aff154e9ed6f23d961"
   },
   "outputs": [],
   "source": [
    "model2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "dd8b5497fa489c35d7ff77319f7d05de46186ac1"
   },
   "source": [
    "We can observe that this model has the same number of parameters and trainable parameters as  the previous model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "b97e8d966f8a369c4503bffd419d57c1d113bd1b"
   },
   "outputs": [],
   "source": [
    "train_model2  = model2.fit_generator(image_generator.flow(X_train, y_train, batch_size=BATCH_SIZE),\n",
    "                        epochs=NO_EPOCHS_2,\n",
    "                        validation_data=[X_val, y_val],\n",
    "                        steps_per_epoch=len(X_train)/BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "2254e9082c703f5744f61bc59018f107aca6757c"
   },
   "source": [
    "### Evaluate model accuracy and loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "9a69aeb83cee0c57a2e362349925ff509c7af7ee"
   },
   "outputs": [],
   "source": [
    "plot_accuracy_and_loss(train_model2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "dc0fb043121e04f92f1af7d7821b8581cca8c572"
   },
   "source": [
    "### Test accuracy and loss\n",
    "\n",
    "Let's evaluare as well the test accuracy and loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "19285aa59a4a6dabbf55e81ebdc235ef50c46411"
   },
   "outputs": [],
   "source": [
    "test_accuracy_report(model2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "349c34acbba6d761b959a0a7a5b31df9abdf722b"
   },
   "source": [
    "<a href=\"#0\"><font size=\"1\">Go to top</font></a>  \n",
    "\n",
    "## <a id='45'>Model refinement</a>  \n",
    "\n",
    "\n",
    "We define now also a refined model. \n",
    "\n",
    "We add an early stopping condition (monitor the loss error and stops the training if for a number of stept given in the `patience` parameters the loss is not improving).\n",
    "\n",
    "We are also saving a model checkpoint after each epoch when accuracy improves; if accuracy degrades, no new model is saved. Thus, Model Checkpoint saves all the time the best model in terms of accuracy.  \n",
    "\n",
    "We adjust as well the learning rate with the training epochs.\n",
    "\n",
    "Also, we increase the number of training epochs to 50.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "deb1e2d4ced60d163ae5257830a3b60dc2d8fc0f"
   },
   "outputs": [],
   "source": [
    "annealer3 = LearningRateScheduler(lambda x: 1e-3 * 0.995 ** (x+NO_EPOCHS_3))\n",
    "earlystopper3 = EarlyStopping(monitor='loss', patience=PATIENCE, verbose=VERBOSE)\n",
    "checkpointer3 = ModelCheckpoint('best_model_3.h5',\n",
    "                                monitor='val_acc',\n",
    "                                verbose=VERBOSE,\n",
    "                                save_best_only=True,\n",
    "                                save_weights_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "83da1405441c237be0537abd81baf8f90638ce40"
   },
   "outputs": [],
   "source": [
    "model3=Sequential()\n",
    "model3.add(Conv2D(CONV_2D_DIM_1, kernel_size=KERNEL_SIZE, input_shape=(IMAGE_WIDTH, IMAGE_HEIGHT,IMAGE_CHANNELS), activation='relu', padding='same'))\n",
    "model3.add(MaxPool2D(MAX_POOL_DIM))\n",
    "# Add dropouts to the model\n",
    "model3.add(Dropout(0.4))\n",
    "model3.add(Conv2D(CONV_2D_DIM_2, kernel_size=KERNEL_SIZE, activation='relu', padding='same'))\n",
    "# Add dropouts to the model\n",
    "model3.add(Dropout(0.4))\n",
    "model3.add(Flatten())\n",
    "model3.add(Dense(y_train.columns.size, activation='softmax'))\n",
    "model3.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "66c5f7c6d62ee01b17b85960456f7b0502415aa8"
   },
   "source": [
    "Let's inspect the refined model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "b521fad3c6db559e77eeee1147f0b7a02fd91a13"
   },
   "outputs": [],
   "source": [
    "model3.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "c773e443457fb4999513b5d0eb7d2454bae419e7"
   },
   "source": [
    "Now, let's train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "a7ac74a25bed9338906effff9d7df171d7b8b154"
   },
   "outputs": [],
   "source": [
    "train_model3  = model3.fit_generator(image_generator.flow(X_train, y_train, batch_size=BATCH_SIZE),\n",
    "                        epochs=NO_EPOCHS_3,\n",
    "                        validation_data=[X_val, y_val],\n",
    "                        steps_per_epoch=len(X_train)/BATCH_SIZE,\n",
    "                        callbacks=[earlystopper3, checkpointer3, annealer3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c1d333286edff47c2452cdd54df91c5ad7959ef7"
   },
   "source": [
    "### Model accuracy and loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "8adfacee0f01e584915a712f0501c105287e70dc"
   },
   "outputs": [],
   "source": [
    "plot_accuracy_and_loss(train_model3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c0a45ee7288e16e571110dd134248ec880ccaadc"
   },
   "source": [
    "### Test accuracy and loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "1ad166de21bdd7e097fb73e64ec564b61358a6c1"
   },
   "outputs": [],
   "source": [
    "test_accuracy_report(model3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "cd6bd3fba3f98e9775dac4f313371af4701febf3"
   },
   "source": [
    "<a href=\"#0\"><font size=\"1\">Go to top</font></a>  \n",
    "\n",
    "# <a id='6'>Conclusions</a>  \n",
    "\n",
    "After exploring the data to understand its various features, a baseline model is created.   \n",
    "Evaluation of the baseline model  results for valid set and test set allows us to decide, based on analysis of bias and variance, how to conduct furher our experiments.\n",
    "\n",
    "From the possible solutions for overfitting, we choose to add Dropout layers. Adding Dropout layers improve a bit the algorithm performance (reduce overfitting).  \n",
    "\n",
    "A third model, with adjustable learning rate, early stoping based on validation accuracy measurement and saving the model with best accuracy was also created. With this model, accuracy of prediction for the test set was further improved.\n",
    "\n",
    "The key lessons learned from this Kernel are the following:   \n",
    "\n",
    "* start by analyzing the data;   \n",
    "* follow with a simple baseline model;   \n",
    "* refine gradually the model, by making corrections based on the analysis of the (partial) results.\n",
    "\n",
    "<a href=\"#0\"><font size=\"1\">Go to top</font></a>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
