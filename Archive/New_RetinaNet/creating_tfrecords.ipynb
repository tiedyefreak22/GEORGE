{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "61fb6501-ebd9-4359-8eed-eb2c2442bc31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
    "import keras\n",
    "import json\n",
    "import pprint\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from os.path import expanduser\n",
    "\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "08fe152a-4d6e-478e-bb5b-aac2bc4ec1ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "## Define TFRecords helper functions\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def image_feature(value):\n",
    "    \"\"\"Returns a bytes_list from a string / byte.\"\"\"\n",
    "    return tf.train.Feature(\n",
    "        bytes_list=tf.train.BytesList(value=[tf.io.encode_png(value).numpy()])\n",
    "    )\n",
    "\n",
    "\n",
    "def bytes_feature(value):\n",
    "    \"\"\"Returns a bytes_list from a string / byte.\"\"\"\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value.encode()]))\n",
    "\n",
    "\n",
    "def float_feature(value):\n",
    "    \"\"\"Returns a float_list from a float / double.\"\"\"\n",
    "    return tf.train.Feature(float_list=tf.train.FloatList(value=[value]))\n",
    "\n",
    "\n",
    "def int64_feature(value):\n",
    "    \"\"\"Returns an int64_list from a bool / enum / int / uint.\"\"\"\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
    "\n",
    "\n",
    "def float_feature_list(value):\n",
    "    \"\"\"Returns a list of float_list from a float / double.\"\"\"\n",
    "    return tf.train.Feature(float_list=tf.train.FloatList(value=value))\n",
    "\n",
    "\n",
    "def create_example(image, path, example):\n",
    "    feature = {\n",
    "        \"image\": image_feature(image),\n",
    "        \"path\": bytes_feature(path),\n",
    "        \"area\": float_feature(example[\"area\"]),\n",
    "        \"bbox\": float_feature_list(example[\"bbox\"]),\n",
    "        \"category_id\": int64_feature(example[\"category_id\"]),\n",
    "        \"id\": int64_feature(example[\"id\"]),\n",
    "        \"image_id\": int64_feature(example[\"image_id\"]),\n",
    "    }\n",
    "    return tf.train.Example(features=tf.train.Features(feature=feature))\n",
    "\n",
    "\n",
    "def parse_tfrecord_fn(example):\n",
    "    feature_description = {\n",
    "        \"image\": tf.io.FixedLenFeature([], tf.string),\n",
    "        \"path\": tf.io.FixedLenFeature([], tf.string),\n",
    "        \"area\": tf.io.FixedLenFeature([], tf.float32),\n",
    "        \"bbox\": tf.io.VarLenFeature(tf.float32),\n",
    "        \"category_id\": tf.io.FixedLenFeature([], tf.int64),\n",
    "        \"id\": tf.io.FixedLenFeature([], tf.int64),\n",
    "        \"image_id\": tf.io.FixedLenFeature([], tf.int64),\n",
    "    }\n",
    "    example = tf.io.parse_single_example(example, feature_description)\n",
    "    example[\"image\"] = tf.io.decode_png(example[\"image\"], channels=3)\n",
    "    example[\"bbox\"] = tf.sparse.to_dense(example[\"bbox\"])\n",
    "    return example\n",
    "\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23bce197-3675-4481-ba14-9b2fd057f307",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images: 1049869\n",
      "{'area': 6300.0,\n",
      " 'bbox': [259.0, 536.0, 70.0, 90.0],\n",
      " 'category_id': 3,\n",
      " 'id': 61,\n",
      " 'image_id': 4,\n",
      " 'iscrowd': 0,\n",
      " 'segmentation': None}\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "The images are a collection of PNG files and the meta-data are stored in a JSON file\n",
    "which, according to the [official site](https://cocodataset.org/#format-data),\n",
    "contains the following properties:\n",
    "\n",
    "```\n",
    "id: int,\n",
    "image_id: int,\n",
    "category_id: int,\n",
    "segmentation: RLE or [polygon], object segmentation mask\n",
    "bbox: [x,y,width,height], object bounding box coordinates\n",
    "area: float, area of the bounding box\n",
    "iscrowd: 0 or 1, is single object or a collection\n",
    "```\n",
    "\"\"\"\n",
    "home = expanduser(\"~\")\n",
    "train_augmented_fp = home + \"/OneDrive/Documents/Github/GEORGE/Dataset/Custom_Dataset/Train\"\n",
    "val_augmented_fp = home + \"/OneDrive/Documents/Github/GEORGE/Dataset/Custom_Dataset/Validation\"\n",
    "test_augmented_fp = home + \"/OneDrive/Documents/Github/GEORGE/Dataset/Custom_Dataset/Test\"\n",
    "tfrecords_dir = home + \"/OneDrive/Documents/Github/GEORGE/Dataset/Custom_Dataset/tfrecords\"\n",
    "\n",
    "if not os.path.exists(tfrecords_dir):\n",
    "    os.makedirs(tfrecords_dir)  # creating TFRecords output folder\n",
    "\n",
    "fps = [train_augmented_fp, val_augmented_fp, test_augmented_fp]\n",
    "\n",
    "for fp in fps:\n",
    "    current_tf_dir = tfrecords_dir + \"/\" + fp.split(\"/\")[-1]\n",
    "    if not os.path.exists(current_tf_dir):\n",
    "        os.makedirs(current_tf_dir)  # creating TFRecords output folder\n",
    "    images_dir = fp\n",
    "    annotations_dir = fp\n",
    "    annotation_file = os.path.join(fp, \"custom_bee_dataset.json\")\n",
    "    \n",
    "    with open(annotation_file, \"r\") as f:\n",
    "        annotations = json.load(f)[\"annotations\"]\n",
    "    \n",
    "    print(f\"Number of images: {len(annotations)}\")\n",
    "    \n",
    "    pprint.pprint(annotations[60])\n",
    "    \n",
    "    \"\"\"\n",
    "    ## Parameters\n",
    "    \n",
    "    `num_samples` is the number of data samples on each TFRecord file.\n",
    "    \n",
    "    `num_tfrecords` is total number of TFRecords that we will create.\n",
    "    \"\"\"\n",
    "    \n",
    "    num_samples = 4096\n",
    "    num_tfrecords = len(annotations) // num_samples\n",
    "    if len(annotations) % num_samples:\n",
    "        num_tfrecords += 1  # add one record if there are any remaining samples\n",
    "\n",
    "    \"\"\"\n",
    "    ## Generate data in the TFRecord format\n",
    "    \n",
    "    Let's generate the COCO2017 data in the TFRecord format. The format will be\n",
    "    `file_{number}.tfrec` (this is optional, but including the number sequences in the file\n",
    "    names can make counting easier).\n",
    "    \"\"\"\n",
    "    \n",
    "    for tfrec_num in range(num_tfrecords):\n",
    "        samples = annotations[(tfrec_num * num_samples) : ((tfrec_num + 1) * num_samples)]\n",
    "    \n",
    "        with tf.io.TFRecordWriter(\n",
    "            current_tf_dir + \"/file_%.2i-%i.tfrec\" % (tfrec_num, len(samples))\n",
    "        ) as writer:\n",
    "            for sample in samples:\n",
    "                image_path = f\"{images_dir}/{sample['image_id']:01d}.png\"\n",
    "                image = tf.io.decode_png(tf.io.read_file(image_path))\n",
    "                example = create_example(image, image_path, sample)\n",
    "                writer.write(example.SerializeToString())\n",
    "    \n",
    "    \"\"\"\n",
    "    ## Explore one sample from the generated TFRecord\n",
    "    \"\"\"\n",
    "    \n",
    "    raw_dataset = tf.data.TFRecordDataset(f\"{current_tf_dir}/file_00-{num_samples}.tfrec\")\n",
    "    parsed_dataset = raw_dataset.map(parse_tfrecord_fn)\n",
    "    \n",
    "    for features in parsed_dataset.take(1):\n",
    "        for key in features.keys():\n",
    "            if key != \"image\":\n",
    "                print(f\"{key}: {features[key]}\")\n",
    "    \n",
    "        print(f\"Image shape: {features['image'].shape}\")\n",
    "        plt.figure(figsize=(7, 7))\n",
    "        plt.imshow(features[\"image\"].numpy())\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48505a15-c939-4b94-9a6b-47ea1e982a91",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
